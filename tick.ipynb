{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e67f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "from enum import Enum\n",
    "from src import scrab_data\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8164947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TICKERS_FOLDER = \"./all_tickers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a79771f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    BUY = 0\n",
    "    SELL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed4f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    _instance = None\n",
    "    stocks_objects = list() # might be useless\n",
    "    all_ticker_dfs = dict() # tickers with corresponding dataframes\n",
    "\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(Environment, cls).__new__(cls)\n",
    "            cls._instance._initialized = False\n",
    "        return cls._instance\n",
    "\n",
    "    def __init__(self):\n",
    "        if not self._initialized:\n",
    "            # Load csv files into memory\n",
    "            files = os.listdir(ALL_TICKERS_FOLDER)\n",
    "            for csv_file in tqdm(files, desc=\"Loading CSVs into memory\", unit=\"files\"):\n",
    "                try:\n",
    "                    df = pd.read_csv(\n",
    "                        os.path.join(ALL_TICKERS_FOLDER, csv_file),\n",
    "                        index_col=\"date\",                     # index column name\n",
    "                        parse_dates=[\"date\"],                 # explicitly parse this column as datetime\n",
    "                    )\n",
    "                    df.index = df.index.normalize()           # remove any time component\n",
    "                    ticker = csv_file.removesuffix(\".csv\")\n",
    "                    self.all_ticker_dfs[ticker] = df\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {csv_file}: {e}\")\n",
    "                    raise RuntimeError\n",
    "            # Only initialize once\n",
    "            self._initialized = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7205c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading CSVs into memory: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2622/2622 [00:56<00:00, 46.15files/s]\n"
     ]
    }
   ],
   "source": [
    "env = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8024d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tickers:\n",
    "    df_tickers = pd.DataFrame()\n",
    "    ticker_file_name = \"tickers.csv\"\n",
    "    url = \"https://app.scrab.com/screener/\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:143.0) Gecko/20100101 Firefox/143.0\",\n",
    "        \"Referer\": \"https://app.scrab.com/screener/\",\n",
    "        \"Origin\": \"https://app.scrab.com\",\n",
    "        \"Hx-Request\": \"true\",\n",
    "        \"X-CSRFToken\": scrab_data.CSRF_TOKEN,\n",
    "    }\n",
    "    cookies = {\n",
    "        \"sessionid\": scrab_data.SESSION_ID,\n",
    "        \"csrftoken\": scrab_data.CSRF_TOKEN\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.df_tickers = pd.read_csv(self.ticker_file_name)\n",
    "            self.df_tickers.index = pd.to_datetime(self.df_tickers.index)\n",
    "        except FileNotFoundError:\n",
    "            self.fetch_tickers()\n",
    "            self.df_tickers.to_csv(self.ticker_file_name, index=False)\n",
    "\n",
    "    def fetch_tickers(self, debug=False):\n",
    "        self.df_tickers = pd.DataFrame()\n",
    "        i = 0\n",
    "\n",
    "        current_rows = self.df_tickers.shape[0]\n",
    "        fetch_more = True\n",
    "\n",
    "        while fetch_more:\n",
    "            fetch_more = False\n",
    "            market_cap_less = None\n",
    "            if current_rows > 0:\n",
    "                self.df_tickers.sort_values(by=\"Market Cap (USD)\", inplace=True, ascending=False, key=lambda x: x.astype(float))\n",
    "                market_cap_less = str(float(self.df_tickers[\"Market Cap (USD)\"].iloc[-1]) - 1)\n",
    "                if debug:\n",
    "                    print(f\"Fetching more tickers with market cap less than {market_cap_less}\")\n",
    "\n",
    "            fetched_tickers_data = self.fetch_data(market_cap_less=market_cap_less)\n",
    "            self.parse_data(fetched_tickers_data)\n",
    "\n",
    "            if debug:\n",
    "                self.df_tickers.to_csv(f\"tickers_page_{i}.csv\", index=False)\n",
    "\n",
    "            if self.df_tickers.shape[0] > current_rows:\n",
    "                fetch_more = True\n",
    "                current_rows = self.df_tickers.shape[0]\n",
    "                i += 1\n",
    "                time.sleep(1)\n",
    "            \n",
    "            if current_rows % 10 != 0:\n",
    "                self.df_tickers.sort_values(by=\"Market Cap (USD)\", inplace=True, ascending=False, key=lambda x: x.astype(float))\n",
    "                print(f\"Fetched {current_rows} tickers, exit loop\")\n",
    "                fetch_more = False\n",
    "\n",
    "    def parse_data(self, html_data):\n",
    "        soup = BeautifulSoup(html_data, 'html.parser')\n",
    "        table = soup.find(\"table\", {\"id\": \"screener-results-table\"})\n",
    "        headers = [th.get_text(strip=True) for th in table.find(\"thead\").find_all(\"th\")][1:]  # skip checkbox\n",
    "\n",
    "        rows = []\n",
    "        for tr in table.find(\"tbody\").find_all(\"tr\"):\n",
    "            tds = tr.find_all(\"td\")[1:]  # skip row number\n",
    "            row = []\n",
    "            for td in tds:\n",
    "                a = td.find(\"a\")\n",
    "                if a:\n",
    "                    row.append(a.get_text(strip=True))\n",
    "                else:\n",
    "                    span = td.find(\"span\")\n",
    "                    if span:\n",
    "                        row.append(span.get_text(strip=True))\n",
    "                    else:\n",
    "                        row.append(td.get_text(strip=True))\n",
    "            rows.append(row)\n",
    "\n",
    "        new_tickers = pd.DataFrame(rows, columns=headers)\n",
    "        new_tickers[\"Revenue Average Estimated Annual Growth in Next 2 Years\"] = new_tickers[\"Revenue Average Estimated Annual Growth in Next 2 Years\"].str.replace(r'[^0-9.]', '', regex=True)\n",
    "        new_tickers[\"EPS Average Estimated Annual Growth in Next 2 Years\"] = new_tickers[\"EPS Average Estimated Annual Growth in Next 2 Years\"].str.replace(r'[^0-9.]', '', regex=True)\n",
    "        new_tickers[\"EPS Long Term (5 Years) Growth Estimates\"] = new_tickers[\"EPS Long Term (5 Years) Growth Estimates\"].str.replace(r'[^0-9.]', '', regex=True)\n",
    "        new_tickers[\"CFO per Share Average Estimated Annual Growth in Next 2 Years\"] = new_tickers[\"CFO per Share Average Estimated Annual Growth in Next 2 Years\"].str.replace(r'[^0-9.]', '', regex=True)\n",
    "\n",
    "        self.df_tickers = pd.concat([self.df_tickers, new_tickers], ignore_index=True)\n",
    "\n",
    "    def fetch_data(self, market_cap_less=None, debug=False):\n",
    "        form_data = {\n",
    "            \"csrfmiddlewaretoken\": scrab_data.CSRF_TOKEN,\n",
    "            \"countries\": '[{\"value\":\"USA\",\"code\":\"us\",\"extra\":\"AMEX, NASDAQ, NYSE\",\"searchBy\":\"NasdaqGS,Global,Capital,New,York,North,America,United,States,AMEX,NASDAQ,NYSE\"}]',\n",
    "            \"market_cap_greater\": \"10000000000\",\n",
    "            \"sales_est_2fy_avg_greater\": \"5\",\n",
    "            \"eps_est_2fy_avg_greater\": \"7\",\n",
    "            \"price_greater\": \"15\",\n",
    "            \"eps_est_2y_num_est_greater\": \"5\",\n",
    "            \"eps_est_long_term_growth_num_est_greater\": \"5\",\n",
    "            \"eps_est_long_term_growth_greater\": \"10\",\n",
    "            \"cfo_per_share_est_2fy_avg_greater\": \"7\",\n",
    "        }\n",
    "        if market_cap_less is not None:\n",
    "            form_data[\"market_cap_less\"] = market_cap_less\n",
    "\n",
    "        response = requests.post(\n",
    "            \"https://app.scrab.com/screener/\",\n",
    "            data=form_data,\n",
    "            headers=self.headers,\n",
    "            cookies=self.cookies\n",
    "        )\n",
    "\n",
    "        if debug:\n",
    "            print(response.status_code)\n",
    "            with open(\"fetch_tickers_response.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response.text)\n",
    "        return response.text\n",
    "\n",
    "    def get_tickers(self):\n",
    "        return self.df_tickers[\"Ticker\"].to_list()\n",
    "\n",
    "# Load or fetch tickers\n",
    "# tickers = Tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a2d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# screener = tickers.get_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "009ea5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stock:\n",
    "    def __init__(self, ticker, fetch_from_scrab=False):\n",
    "        env = Environment()\n",
    "        self.expensiveness_coeff = 1.2\n",
    "\n",
    "        self.ticker = ticker\n",
    "        self.df = pd.DataFrame()\n",
    "        self.trela_indicator = None\n",
    "\n",
    "        if fetch_from_scrab:\n",
    "            # Fetch Strategy metrics\n",
    "            self.fetch_metric(\"price\")\n",
    "            self.fetch_metric(\"price_target\")\n",
    "            self.fetch_metric(\"price_target_upside\")\n",
    "            self.fetch_metric(\"forward_pe_ratio\")\n",
    "            self.fetch_metric(\"forward_pe_ratio:median:3\")\n",
    "            self.fetch_metric(\"forward_ps_ratio\")    \n",
    "            self.fetch_metric(\"forward_ps_ratio:median:3\")\n",
    "            # Fetch Screener metrics\n",
    "            self.fetch_metric(\"market_cap\")\n",
    "            self.fetch_metric(\"sales_est_2fy_avg\")\n",
    "            self.fetch_metric(\"eps_est_2fy_avg\")\n",
    "            self.fetch_metric(\"eps_est_2y_num_est\")\n",
    "            self.fetch_metric(\"eps_est_long_term_growth_num_est\")\n",
    "            self.fetch_metric(\"eps_est_long_term_growth\")\n",
    "            self.fetch_metric(\"cfo_per_share_est_2fy_avg\")\n",
    "        else:\n",
    "            self.df = env.all_ticker_dfs[ticker]\n",
    "\n",
    "        # Placeholder metrics\n",
    "        # Initialize buy / sell to false\n",
    "        for col in ['buy', 'sell']:\n",
    "            if col not in self.df.columns:\n",
    "                self.df[col] = False\n",
    "                \n",
    "        self.postprocess_metrics()\n",
    "        env.stocks_objects.append(self)\n",
    "\n",
    "    def fetch_metric(self, metric):\n",
    "        try:\n",
    "            response_metric = self._request_data(self.ticker, metric)\n",
    "            datapoints = response_metric[0]['datapoints']\n",
    "            \n",
    "            metric_df = pd.DataFrame(datapoints, columns=['timestamp', metric])\n",
    "            metric_df.insert(0, 'date', pd.to_datetime(metric_df['timestamp'], unit='s'))\n",
    "            metric_df = metric_df.drop(columns='timestamp')\n",
    "\n",
    "        except (IndexError, KeyError, TypeError, ValueError) as e:\n",
    "            # Handle missing or malformed data\n",
    "            print(f\"[Warning] Failed to fetch metric '{metric}' for {self.ticker}: {e}\")\n",
    "\n",
    "            # Insert zeros aligned with existing df dates, or just create a dummy df\n",
    "            if self.df.empty:\n",
    "                # No existing dates â€” create dummy one-row entry with today's date\n",
    "                metric_df = pd.DataFrame({\n",
    "                    'date': [pd.Timestamp.today()],\n",
    "                    metric: [np.nan]\n",
    "                })\n",
    "            else:\n",
    "                # Add column of 0s for existing dates\n",
    "                metric_df = pd.DataFrame({\n",
    "                    'date': self.df['date'],\n",
    "                    metric: [np.nan] * len(self.df)\n",
    "                })\n",
    "\n",
    "        for col in self.df.columns:\n",
    "            if col != 'date' and self.df[col].isna().all():\n",
    "                print(f\"[Warning] Column '{col}' is all NaN\")\n",
    "\n",
    "\n",
    "        # Merge the metric into self.df\n",
    "        if self.df.empty:\n",
    "            self.df = metric_df\n",
    "        else:\n",
    "            self.df = pd.merge(self.df, metric_df, on='date', how='left')\n",
    "\n",
    "\n",
    "    def postprocess_metrics(self):\n",
    "        # Forward fill price targets\n",
    "        self.df['price_target'] = self.df['price_target'].ffill()\n",
    "        self.get_trend(\"price_target\", add_to_dataframe=True)\n",
    "        # self.calculate_trela_indicator() // out of date, update!\n",
    "\n",
    "    def _request_data(self, ticker, metric):\n",
    "        url = \"https://app.scrab.com/data/metric/\"\n",
    "        payload = {\n",
    "        \"tickers\":[ticker],\n",
    "        \"metrics\":[metric],\n",
    "        \"economic\":[],\n",
    "        \"index\":1\n",
    "        }\n",
    "        cookies = {\n",
    "            \"sessionid\": scrab_data.SESSION_ID,\n",
    "            \"csrftoken\": scrab_data.CSRF_TOKEN\n",
    "        }\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"User-Agent\": \"Mozilla/5.0\",\n",
    "            \"X-CSRFToken\": scrab_data.CSRF_TOKEN,\n",
    "            \"Referer\": \"https://app.scrab.com/charts/master/\",\n",
    "            \"Origin\": \"https://app.scrab.com\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers, cookies=cookies)\n",
    "        data = response.json()\n",
    "        return data\n",
    "  \n",
    "    def plot(self, title, metrics, log_scale=False, start_date=\"1900-01-01\", save=False):\n",
    "        df_plot = self.df.loc[start_date:]\n",
    "        fig, ax = plt.subplots(figsize=(12,6))\n",
    "        for metric in metrics:\n",
    "            ax.plot(df_plot.index, df_plot[metric], label=metric)\n",
    "            ax.set_title(title)\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel(str(metrics))\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            if log_scale:\n",
    "                ax.set_yscale('log')  # make y-axis logarithmic\n",
    "        if (save):\n",
    "            charts_dir = \"./charts\"\n",
    "            os.makedirs(charts_dir, exist_ok=True)  # ensure folder exists\n",
    "            chart_path = os.path.join(charts_dir, f\"{self.ticker}.png\")\n",
    "            fig.savefig(chart_path, bbox_inches=\"tight\")\n",
    "            plt.close(fig)  # close to free memory if plotting multiple charts\n",
    "        return ax\n",
    "\n",
    "    def calculate_rolling_sigma_bands(self, metric, window_upper, window_lower, sigma_coeff = 2.0, smooth_window=1):\n",
    "        min_periods = max(window_upper, window_lower) \n",
    "        # rolling mean & std\n",
    "        mean_upper = self.df[metric].rolling(window_upper, min_periods=window_upper).mean()\n",
    "        std_upper = self.df[metric].rolling(window_upper, min_periods=window_upper).std()\n",
    "        mean_lower = self.df[metric].rolling(window_lower, min_periods=window_lower).mean()\n",
    "        std_lower = self.df[metric].rolling(window_lower, min_periods=window_lower).std()\n",
    "        # bands\n",
    "        self.df[metric + '_upper_band'] = mean_upper + sigma_coeff * std_upper\n",
    "        self.df[metric + '_lower_band'] = mean_lower - sigma_coeff * std_lower\n",
    "        # smooth\n",
    "        self.df[metric + '_upper_band'] = self.df[metric + '_upper_band'].rolling(smooth_window, min_periods=1).mean()\n",
    "        self.df[metric + '_lower_band'] = self.df[metric + '_lower_band'].rolling(smooth_window, min_periods=1).mean()\n",
    "        # drop unpopulated rows\n",
    "        # self.df.dropna(subset=[metric + '_upper_band', metric + '_lower_band'], inplace=True)\n",
    "    \n",
    "    def get_sigma(self, metric, window=252):\n",
    "        sigma_coeff = 1.0\n",
    "        mean = self.df[metric].tail(window).mean()\n",
    "        std = self.df[metric].tail(window).std()\n",
    "        upper_band = mean + sigma_coeff * std\n",
    "        lower_band = mean - sigma_coeff * std\n",
    "        return mean, std, upper_band, lower_band\n",
    "\n",
    "    def get_trend(self, metric, window=252, add_to_dataframe=False, debug=False):\n",
    "        # TODO do this for the entire df, not only last value\n",
    "        series = self.df[metric].tail(window)\n",
    "        # Drop NaNs\n",
    "        y = series.dropna().to_numpy()\n",
    "        if len(y) < 2:\n",
    "            if debug:\n",
    "                print(f\"[Warning] Not enough data to calculate trend for '{metric}' (only {len(y)} points).\")\n",
    "            if add_to_dataframe:\n",
    "                self.df.loc[self.df.index[-window:], metric + '_trend'] = np.nan\n",
    "            return\n",
    "        X = np.arange(len(y)).reshape(-1, 1)\n",
    "        model = LinearRegression().fit(X, y)\n",
    "        \n",
    "        # create trend line points so it can be plotted\n",
    "        # and add it to the dataframe\n",
    "        if add_to_dataframe:\n",
    "            trend_data_points = model.predict(X)\n",
    "            trend_series = pd.Series(np.nan, index=series.index)\n",
    "            trend_series.iloc[-len(y):] = trend_data_points\n",
    "            self.df.loc[self.df.index[-window:], metric + '_trend'] = trend_series\n",
    "\n",
    "        if debug:\n",
    "            print(model.coef_)\n",
    "            print(model.intercept_)\n",
    "        return model.coef_[0] > 0\n",
    "    \n",
    "    # to calculate Trela Indicator we need to calculate in order:\n",
    "    # 1. Is the stock expensive? - forward_pe_ratio > 1.2 * forward_pe_ratio:median:3\n",
    "    #                              forward_ps_ratio > 1.2 * forward_ps_ratio:median:3\n",
    "    # FOR NOW WE WILL CHECK IF forward_pe_ratio > than forward_pe_ratio + sigma_coeff\n",
    "    # 2. Is price target upside very low? - price_target_upside < lower_band (1.75 sigma)\n",
    "    # 3. Is price target trend positive? - get_trend(\"price_target\", window=252) > 0\n",
    "    def calculate_trela_indicator(self, debug=False):\n",
    "        # TODO do this for the entire df, not only last value\n",
    "        latest_pe_ratio = self.df['forward_pe_ratio'].iloc[-1]\n",
    "        latest_pe_ratio_median = self.df['forward_pe_ratio:median:3'].iloc[-1]\n",
    "        latest_ps_ratio = self.df['forward_ps_ratio'].iloc[-1]\n",
    "        latest_ps_ratio_median = self.df['forward_ps_ratio:median:3'].iloc[-1]\n",
    "\n",
    "        if pd.isna(latest_pe_ratio) or pd.isna(latest_pe_ratio_median):\n",
    "            print(f\"[Warning] Skipping Trela indicator for {self.ticker} due to missing PE ratio data.\")\n",
    "            return\n",
    "\n",
    "        is_very_expensive = False\n",
    "        if latest_pe_ratio > latest_pe_ratio_median * self.expensiveness_coeff\\\n",
    "        or latest_ps_ratio > latest_ps_ratio_median * self.expensiveness_coeff:\n",
    "            is_very_expensive = True\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"{self.ticker} - latest_pe_ratio: {latest_pe_ratio}, \"\n",
    "                  f\"latest_pe_ratio_median: {latest_pe_ratio_median}, \"\n",
    "                  f\"latest_ps_ratio: {latest_ps_ratio}, \"\n",
    "                  f\"latest_ps_ratio_median: {latest_ps_ratio_median}, \"\n",
    "                  f\"expensiveness_coeff: {self.expensiveness_coeff}, \"\n",
    "                  f\"is_very_expensive: {is_very_expensive}\"\n",
    "            )\n",
    "        \n",
    "        latest_upside_lower_band = self.get_sigma(\"price_target_upside\", window=126)[-1]\n",
    "        latest_upside = self.df['price_target_upside'].iloc[-1]\n",
    "        is_upside_very_low = latest_upside < latest_upside_lower_band\n",
    "\n",
    "        is_price_target_trend_positive = self.get_trend(\"price_target\", window=252)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"{self.ticker} - latest_upside: {latest_upside}, \"\n",
    "                  f\"latest_upside_lower_band: {latest_upside_lower_band}, \"\n",
    "                  f\"is_upside_very_low: {is_upside_very_low}, \"\n",
    "                  f\"is_price_target_trend_positive: {is_price_target_trend_positive}\"\n",
    "            )\n",
    "\n",
    "        if is_very_expensive:\n",
    "            if is_upside_very_low:\n",
    "                self.trela_indicator = \"SELL\"\n",
    "            else:\n",
    "                self.trela_indicator = \"HOLD\"\n",
    "        else:\n",
    "            if is_upside_very_low:\n",
    "                if is_price_target_trend_positive:\n",
    "                    self.trela_indicator = \"HOLD\"\n",
    "                else:\n",
    "                    self.trela_indicator = \"SELL\"\n",
    "            else:\n",
    "                self.trela_indicator = \"HOLD\"\n",
    "\n",
    "        if debug:\n",
    "            print(f\"{self.ticker} - Trela Indicator: {self.trela_indicator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac9cddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tickers = list()\n",
    "# all_tickers_path = \"all_tickers.json\"\n",
    "# with open(all_tickers_path, \"r\") as f:\n",
    "#     companies = json.load(f)\n",
    "# all_tickers = [entry[\"ticker\"] for entry in companies]\n",
    "# if os.path.isdir(\"./all_tickers_raw\"):\n",
    "#         print(\"Folder exists!\")\n",
    "# else:\n",
    "#     os.makedirs(\"all_tickers_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a8af729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES A LOT OF TIME:\n",
    "# for ticker in tickers:\n",
    "#     if os.path.isfile(\"./all_tickers_raw/\" + ticker + \".csv\"):\n",
    "#         continue\n",
    "#     print(f\"fetching {ticker}\")\n",
    "#     current_ticker = Stock(ticker, for_screening=True)\n",
    "#     current_ticker.df.to_csv(f\"all_tickers_raw/{ticker}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "598860c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipped_tickers = list()\n",
    "# for ticker in tqdm(all_tickers, desc=\"Processing tickers\"):\n",
    "#     try:\n",
    "#         df = pd.read_csv(f\"./all_tickers_raw/{ticker}.csv\")\n",
    "#         # Drop useless columns:\n",
    "#         df.drop(['buy', 'sell', 'price_target_trend'], axis=1, inplace=True)\n",
    "#         df.ffill(inplace=True)\n",
    "\n",
    "#         first_valid_idx = df.dropna().first_valid_index()\n",
    "#         if first_valid_idx is None:\n",
    "#             skipped_tickers.append(ticker)\n",
    "#             continue\n",
    "#         df_trimmed = df.loc[first_valid_idx:].reset_index(drop=True)\n",
    "\n",
    "#         if not os.path.isdir(\"./all_tickers\"):\n",
    "#             os.makedirs(\"all_tickers\")\n",
    "            \n",
    "#         df_trimmed.to_csv(f\"all_tickers/{ticker}.csv\", index=False)\n",
    "#     except Exception as e:\n",
    "#         tqdm.write(f\"[{ticker}] âŒ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3e1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ticker in all_tickers:\n",
    "#     try:\n",
    "#         df = pd.read_csv(f\"./all_tickers/{ticker}.csv\")\n",
    "#         df.drop(df.columns[0], axis=1, inplace=True)\n",
    "#         df.to_csv(f\"all_tickers/{ticker}.csv\", index=False)\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe78f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ticker in screener:\n",
    "#     stock = Stock(ticker)\n",
    "#     latest_upside = stock.df['price_target_upside'].iloc[-1]\n",
    "#     latest_upper_band = stock.df['price_target_upside_upper_band'].iloc[-1]\n",
    "#     latest_lower_band = stock.df['price_target_upside_lower_band'].iloc[-1]\n",
    "#     if latest_upside >= latest_upper_band:\n",
    "#         print(f\"{stock.ticker}: BUY -- Upside {latest_upside:.2f}, {latest_upside-latest_upper_band:.1f}% better than 2 sigma. Trela indicator: {stock.trela_indicator}\")\n",
    "#         ax = stock.plot(\n",
    "#         stock.ticker,\n",
    "#         [\"price_target_upside\", \"price_target_upside_upper_band\", \"price_target_upside_lower_band\"],\n",
    "#         start_date=\"2020-01-01\"\n",
    "#         )\n",
    "#     if latest_upside <= latest_lower_band:\n",
    "#         print(f\"{stock.ticker}: SELL -- Upside {latest_upside:.2f}, {latest_lower_band-latest_upside:.1f}% worse than 2 sigma. Trela indicator: {stock.trela_indicator}\")\n",
    "#         ax = stock.plot(\n",
    "#         stock.ticker,\n",
    "#         [\"price_target_upside\", \"price_target_upside_upper_band\", \"price_target_upside_lower_band\"],\n",
    "#         start_date=\"2020-01-01\"\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe06b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Screener:\n",
    "    def __init__(self):\n",
    "        self.env = Environment()\n",
    "            \n",
    "    def run(self, target_date):\n",
    "        screener_tickers = list()\n",
    "        for ticker, df in self.env.all_ticker_dfs.items():\n",
    "            try:\n",
    "                day_data = df.loc[target_date]\n",
    "            except:\n",
    "                continue\n",
    "            row = day_data  # The single row for that date\n",
    "            year = pd.to_datetime(target_date).year\n",
    "            conditions = [\n",
    "                # Adjusted marketcap (10B in 2025)\n",
    "                row[\"market_cap\"] >= self._adjust_market_cap_threshold(year),\n",
    "\n",
    "                # Revenue Average Estimated Annual Growth in 2 Years > 5%\n",
    "                row[\"sales_est_2fy_avg\"] > 5,\n",
    "\n",
    "                # EPS Average Estimated Annual Growth in Next 2 Years > 7%\n",
    "                row[\"eps_est_2y_num_est\"] > 7,\n",
    "\n",
    "                # Price > 5\n",
    "                row[\"price\"] > 5,\n",
    "\n",
    "                # EPS Number Estimates for 2 Fiscal Years Ahead > 5\n",
    "                row[\"eps_est_2fy_avg\"] > 5,\n",
    "\n",
    "                # EPS Long Term (5 Years) Growth Number Estimates > 5\n",
    "                row[\"eps_est_long_term_growth_num_est\"] > 5,\n",
    "\n",
    "                # EPS Long Term (5 Years) Growth Estimates > 10%\n",
    "                row[\"eps_est_long_term_growth\"] > 10,\n",
    "\n",
    "                # CFO per Share Average Estimated Annual Growth in Next 2 Years > 7%\n",
    "                row[\"cfo_per_share_est_2fy_avg\"] > 7,\n",
    "            ]\n",
    "            if all(conditions):\n",
    "                screener_tickers.append(ticker)\n",
    "            else:\n",
    "                pass\n",
    "        return screener_tickers\n",
    "\n",
    "    def _adjust_market_cap_threshold(self, target_year, base_threshold=10e9, base_year=2025):\n",
    "        sp500_market_cap = {\n",
    "            2000: 15,\n",
    "            2001: 13,\n",
    "            2002: 11,\n",
    "            2003: 14,\n",
    "            2004: 16,\n",
    "            2005: 17,\n",
    "            2006: 19,\n",
    "            2007: 19,\n",
    "            2008: 11,\n",
    "            2009: 15,\n",
    "            2010: 17,\n",
    "            2011: 15,\n",
    "            2012: 18,\n",
    "            2013: 14,\n",
    "            2014: 18,\n",
    "            2015: 17,\n",
    "            2016: 19,\n",
    "            2017: 22,\n",
    "            2018: 21,\n",
    "            2019: 26,\n",
    "            2020: 31,\n",
    "            2021: 40,\n",
    "            2022: 32,\n",
    "            2023: 40,\n",
    "            2024: 49,\n",
    "            2025: 57,    # Unsure if this is 100% correct but doesn't really matter\n",
    "        }\n",
    "        \n",
    "        if sp500_market_cap is None:\n",
    "            raise ValueError(\"Please provide a market cap dictionary\")\n",
    "\n",
    "        if target_year not in sp500_market_cap or base_year not in sp500_market_cap:\n",
    "            raise ValueError(f\"Missing data for year {target_year} or {base_year}\")\n",
    "\n",
    "        ratio = sp500_market_cap[target_year] / sp500_market_cap[base_year]\n",
    "        return base_threshold * ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "792fc9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy:\n",
    "    def __init__(self, ticker, date, buy_rule, sell_rule):\n",
    "        self.stock = Stock(ticker)\n",
    "        self.date = pd.to_datetime(date).normalize()\n",
    "        self.prepare_metrics()\n",
    "        self.buy_rule = buy_rule    # function: row -> bool\n",
    "        self.sell_rule = sell_rule  # function: row -> bool\n",
    "\n",
    "    def prepare_metrics(self):\n",
    "        self.stock.calculate_rolling_sigma_bands(\"price_target_upside\", 504, 252, 2, 504)\n",
    "        # self.stock.plot(self.stock.ticker, [\"price_target_upside\", \"price_target_upside_upper_band\", \"price_target_upside_lower_band\"])\n",
    "        pass\n",
    "\n",
    "    def should_buy(self, row):\n",
    "        return self.buy_rule(row)\n",
    "\n",
    "    def should_sell(self, row):\n",
    "        return self.sell_rule(row)\n",
    "    \n",
    "    def execute(self):\n",
    "        df = self.stock.df\n",
    "        # Try to get the row with given date, on KeyError do nothing.\n",
    "        # Some manually adjusted csvs will throw an exception here, after testing it looks OK\n",
    "        try:\n",
    "            row = df.loc[self.date]\n",
    "        except KeyError:\n",
    "            return\n",
    "        if self.should_buy(row):\n",
    "            return Action.BUY\n",
    "        elif self.should_sell(row):\n",
    "            return Action.SELL\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e90414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Position:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        self.size = 0\n",
    "    \n",
    "    def open(self, ticker, size, entry_date, entry_price):\n",
    "        self.size += size\n",
    "        \n",
    "    def close(self, ticker, size, exit_date, exit_price):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc35b3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Portfolio:\n",
    "    def __init__(self):\n",
    "        self.balance = 0\n",
    "        self.total_cash_invested = 0\n",
    "        self.open_positions = dict()\n",
    "        self.env = Environment()\n",
    "\n",
    "    def deposit(self, value):\n",
    "        self.balance += value\n",
    "        self.total_cash_invested += value\n",
    "\n",
    "    def open_position(self, ticker, position_value, date):\n",
    "         # check if you have enough funds\n",
    "        if position_value > self.balance:\n",
    "            print(\"Not enough balance to open position.\")\n",
    "            return\n",
    "        \n",
    "        # deduct the used funds\n",
    "        self.balance -= position_value\n",
    "\n",
    "        # get price and number of shares\n",
    "        df = env.all_ticker_dfs[ticker]\n",
    "        stock_price = df.loc[date][\"price\"]\n",
    "        num_shares = position_value / stock_price\n",
    "\n",
    "        # add to open positions\n",
    "        self.open_positions[ticker] = self.open_positions.get(ticker, 0) + num_shares\n",
    "\n",
    "    def close_position(self, ticker, position_fraction, date):\n",
    "        if ticker not in self.open_positions:\n",
    "            # print(f\"No open position in {ticker}.\")\n",
    "            return\n",
    "\n",
    "        if not (0 < position_fraction <= 1):\n",
    "            print(\"position_fraction must be between 0 and 1.\")\n",
    "            return\n",
    "\n",
    "        df = self.env.all_ticker_dfs[ticker]\n",
    "        stock_price = df.loc[date][\"price\"]\n",
    "\n",
    "        current_shares = self.open_positions[ticker]\n",
    "        shares_to_sell = current_shares * position_fraction\n",
    "        sale_value = shares_to_sell * stock_price\n",
    "\n",
    "        # update portfolio\n",
    "        self.balance += sale_value\n",
    "        self.open_positions[ticker] = current_shares - shares_to_sell\n",
    "\n",
    "        # remove ticker if position fully closed\n",
    "        if self.open_positions[ticker] < 1e-8:\n",
    "            del self.open_positions[ticker]\n",
    "\n",
    "    def get_total_account_value(self, date):\n",
    "        \"\"\"\n",
    "        Returns total account value: cash balance + market value of open positions\n",
    "        `date` should be a pd.Timestamp (or same type as your env prices index)\n",
    "        \"\"\"\n",
    "        total_value = self.balance\n",
    "\n",
    "        for ticker, num_shares in self.open_positions.items():\n",
    "            df = self.env.all_ticker_dfs[ticker]\n",
    "            stock_price = df.loc[date][\"price\"]\n",
    "            total_value += num_shares * stock_price\n",
    "\n",
    "        return total_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a5859d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scorer:\n",
    "    def __init__(self, stocks, criteria):\n",
    "        self.stocks = stocks\n",
    "        # What criteria?\n",
    "        self.criteria = criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d5321053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssetAllocator:\n",
    "    def __init__(self, stocks, allocation):\n",
    "        self.stocks = stocks\n",
    "        self.stock_to_allocation = dict()\n",
    "        allowed_allocation = {'equal_weights'}\n",
    "        if allocation not in allowed_allocation:\n",
    "            raise ValueError(f'allocation must be one of {allowed_allocation}, got {allocation}')\n",
    "        self.allocation = allocation\n",
    "\n",
    "        match self.allocation:\n",
    "            case 'equal_weights':\n",
    "                n = len(self.stocks)\n",
    "                self.stock_to_allocation = {stock: 1 / n for stock in stocks}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486cbfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running simulation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3968/3968 [00:00<00:00, 5294.97days/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL_CASH_INVESTED:  82000\n",
      "PORTFOLIO_BALANCE:  0.0\n",
      "PORTFOLIO VALUE:  255090.73743444227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class Backtester:\n",
    "    def __init__(self, strategy, start_date = \"2010-01-01\", save_strategy=False):\n",
    "      self.strategy = strategy\n",
    "      self.simulation_date = pd.to_datetime(start_date)\n",
    "      self.save_strategy = save_strategy\n",
    "      self.f_strategy = None\n",
    "      self.last_date = pd.to_datetime(\"2025-10-10\") # Last date from downloaded tickers\n",
    "      self.screener_df = pd.DataFrame()\n",
    "      self.strategy_df = pd.DataFrame()\n",
    "      self.date_to_screened_tickers = dict()\n",
    "      self.screener_out_path = \"./screener_out.csv\"\n",
    "      self.strategy_out_path = \"./strategy_out.csv\"\n",
    "      self.run_screener = False\n",
    "      self.run_strategy = False\n",
    "      self.portfolio = Portfolio()\n",
    "\n",
    "      self.last_deposit_date = None\n",
    "      self.deposit_interval = pd.Timedelta(days=7)\n",
    "\n",
    "      if os.path.isfile(self.screener_out_path):\n",
    "        self.screener_df = pd.read_csv(self.screener_out_path)\n",
    "        self.screener_df['date'] = pd.to_datetime(self.screener_df['date'])\n",
    "        self.screener_df['tickers'] = self.screener_df['tickers'].apply(ast.literal_eval)\n",
    "        self.date_to_screened_tickers = dict(zip(self.screener_df['date'], self.screener_df['tickers']))\n",
    "      else:\n",
    "        self.run_screener = True\n",
    "        self.screener = Screener()\n",
    "        \n",
    "      if os.path.isfile(self.strategy_out_path):\n",
    "        self.strategy_df = pd.read_csv(self.strategy_out_path)\n",
    "        self.strategy_df['date'] = pd.to_datetime(self.strategy_df['date'])\n",
    "        self.strategy_df['buy_list'] = self.strategy_df['buy_list'].apply(ast.literal_eval)\n",
    "        self.strategy_df['sell_list'] = self.strategy_df['sell_list'].apply(ast.literal_eval)\n",
    "        self.strategy_df.set_index('date', inplace=True)\n",
    "      else:\n",
    "        self.run_strategy = True\n",
    "        self.f_strategy = open(self.strategy_out_path, mode=\"w\", newline=\"\", encoding=\"utf-8\")\n",
    "        self.strategy_writer = csv.writer(self.f_strategy)\n",
    "        self.strategy_writer.writerow([\"date\", \"buy_list\", \"sell_list\"])\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "      # 1. Run Screener\n",
    "      total_days = (self.last_date - self.simulation_date).days\n",
    "      if self.run_screener:\n",
    "        for _ in tqdm(range(total_days), desc=\"Screening\", unit=\"days\"):\n",
    "          screener_tickers = self.screener.run(self.simulation_date)\n",
    "          if screener_tickers:\n",
    "            self.date_to_screened_tickers[self.simulation_date] = screener_tickers\n",
    "          self.simulation_date += pd.Timedelta(days=1)\n",
    "        # Neatly save to .csv\n",
    "        self.screener_df = pd.DataFrame([{'date': date, 'tickers': tickers} for date, tickers in self.date_to_screened_tickers.items()])\n",
    "        self.screener_df['date'] = self.screener_df['date'].astype(str)\n",
    "        self.screener_df.to_csv(self.screener_out_path, index=False)\n",
    "\n",
    "      # 2. Run Simulation\n",
    "      for date, ticker_list in tqdm(self.date_to_screened_tickers.items(), total=len(self.date_to_screened_tickers), desc=\"Running simulation\", unit=\"days\"):\n",
    "        \n",
    "        # ðŸ’° Deposit every 7 calendar days\n",
    "        if self.last_deposit_date is None or (date - self.last_deposit_date) >= self.deposit_interval:\n",
    "            self.portfolio.deposit(100)\n",
    "            self.last_deposit_date = date\n",
    "        # Strategy\n",
    "        buy_rule = lambda row: row['price_target_upside'] > row['price_target_upside_upper_band']\n",
    "        sell_rule = lambda row: row['price_target_upside'] < row['price_target_upside_lower_band']\n",
    "        buy_list = list()\n",
    "        sell_list = list()\n",
    "        if self.run_strategy:\n",
    "            # Run strategy from scratch\n",
    "            for ticker in ticker_list:\n",
    "                strategy = Strategy(ticker, date, buy_rule, sell_rule)\n",
    "                action = strategy.execute()\n",
    "                if action is Action.BUY:\n",
    "                    buy_list.append(ticker)\n",
    "                elif action is Action.SELL:\n",
    "                    sell_list.append(ticker)\n",
    "            self.strategy_writer.writerow([date.date(), buy_list, sell_list])\n",
    "            self.f_strategy.flush()\n",
    "        else:\n",
    "            # Run strategy from file\n",
    "            buy_list = self.strategy_df.loc[date]['buy_list']\n",
    "            sell_list = self.strategy_df.loc[date]['sell_list']\n",
    "      # 5. Run Scorer\n",
    "        # how should it work?\n",
    "      # 6. Run Portioner\n",
    "        asset_allocator = AssetAllocator(buy_list, \"equal_weights\")\n",
    "      # 7. Simulate buy/sell\n",
    "        for stock, allocation in asset_allocator.stock_to_allocation.items():\n",
    "            self.portfolio.open_position(stock, self.portfolio.balance*allocation, date)\n",
    "        for stock in sell_list:\n",
    "            self.portfolio.close_position(stock, 1, date)\n",
    "      # 8. Calculate portfolio metrics   \n",
    "      print(f\"TOTAL_CASH_INVESTED: {self.portfolio.total_cash_invested:.2f}\")\n",
    "      print(f\"PORTFOLIO_BALANCE: {self.portfolio.balance:.2f}\")\n",
    "      print(f\"PORTFOLIO VALUE: {self.portfolio.get_total_account_value(self.last_date):.2f}\") \n",
    "      # 9. Cleanup\n",
    "      if self.f_strategy is not None:\n",
    "        self.f_strategy.close()\n",
    "            \n",
    "\n",
    "allocation = 'equal_weights'\n",
    "# strategy = Strategy(buy_rule, sell_rule)\n",
    "backtester = Backtester(None)\n",
    "backtester.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f77ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4s na sucho\n",
    "# 90s z backtesterem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
